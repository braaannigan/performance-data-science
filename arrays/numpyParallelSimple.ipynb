{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ebf29e-fe09-438c-b611-935ce387fe52",
   "metadata": {},
   "source": [
    "# Parallel loops through numpy arrays\n",
    "We look at speeding up loops through numpy arrays. In this example we have to call a third-party library in each iteration and this third-party library will only accept a subset of our total array. As we are calling a third-party library we can't apply tricks like JIT compilation.\n",
    "\n",
    "The scenario here is that we have a 3-dimensional array with dimensions (x,y,time). We will imagine that this is a time series of 2-dimensional maps of ocean salinity. Our third-party library is the seawater library. This seawater library only accepts 2-dimensional inputs so we need to loop through the time dimension and call this library on each iteration. \n",
    "\n",
    "# Libraries\n",
    "In this example we will use the built-in [Concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html), [Joblib](https://joblib.readthedocs.io/en/latest/) and [Dask](https://docs.dask.org/en/stable/) libraries.  In the case of Dask we are using the dask delayed API for parallelising the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4ae17f-fa1a-4670-9a03-71183b9579e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor\n",
    "\n",
    "from joblib import Parallel,delayed\n",
    "import dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a956b9c-6a82-48d3-8b65-0204f7305d9f",
   "metadata": {},
   "source": [
    "# Generate data\n",
    "We generate the numpy array we're going to loop through. \n",
    "\n",
    "We use a three-dimensional array where we'll think of the dimensions as being `(x,y,time)`. The function that we're calling, however, can only accept two-dimensional inputs in `(x,y)` so we will loop through the `time` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a997fbf8-d1f3-42e6-a3d8-ad51a1da6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(xyLength:int,timesteps:int):\n",
    "    arr = np.random.standard_normal(size=(xyLength,xyLength,timesteps))\n",
    "    return arr\n",
    "\n",
    "arraySmall = generateData(xyLength=3,timesteps=3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b9265-0b8b-45e2-91ae-e121272c9b9d",
   "metadata": {},
   "source": [
    "We define the function that we are going to call in each iteration `timestepFunc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7576fb64-c8d4-4e7b-86b7-3eab94713360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestepFunc(arrTimestep:np.ndarray,timeIndex:int):\n",
    "    return np.exp(arrTimestep),timeIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225718b0-aef7-4f09-81d6-41a47a217e98",
   "metadata": {},
   "source": [
    "#### First we create a baseline non-parallelised function to do sequential processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0004a8-3687-4389-bc62-ca056d9afa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialProcessing(arr:np.ndarray):\n",
    "    return np.stack(\n",
    "        [timestepFunc(arrTimestep=arr[:,:,timestep],timeIndex=timestep)[0] for timestep in range(arr.shape[2])],\n",
    "        axis=2)\n",
    "\n",
    "# Call the function\n",
    "outputSerial = serialProcessing(arr=arraySmall)\n",
    "# Check the outputs are what we expect\n",
    "np.testing.assert_array_equal(outputSerial,np.exp(arraySmall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df9d06-cf08-4d1f-aa88-f902cf003ac3",
   "metadata": {},
   "source": [
    "#### The outputs of parallel functions are not in the same order as the inputs\n",
    "\n",
    "#### Before we create parallel functions we define a helper function that will sort the list of outputs using the time index variable we added to `timestepFunc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a1d4bd-943a-4230-8148-9e747ca2dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortResults(resultList:list):\n",
    "    resultList = sorted(resultList,key=lambda x:x[1])\n",
    "    resultList = [el[0] for el in resultList]\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e179e6-292b-4e77-b62a-81d083f5415f",
   "metadata": {},
   "source": [
    "# Parallel processing\n",
    "\n",
    "## Concurrent.futures\n",
    "\n",
    "##### The built-in concurrent.futures module is a great place to start with parallel processing. It comes with both a threading and multiprocessing backend. The APIs for these backends are similar, so it's also easy to swap them out and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17c634f-6448-4502-8007-98d4562b32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concurrentProcessing(arr:np.ndarray,executor):\n",
    "    \"\"\"\n",
    "    Iterate through the array `arr` in parallel with either the threading executor or the multiprocessing executor\n",
    "    \"\"\"\n",
    "#     Create the list that will hold the results of each iteration\n",
    "    resultList = []\n",
    "#     Set up the executor \n",
    "#   we use a with statement here to ensure the pool of threads/processes gets closed whether the jobs run successfully or not\n",
    "    with executor() as pool:\n",
    "#         Loop through the array and store the `futures` that we get from each iteration\n",
    "        futuresList = [\n",
    "             pool.submit(\n",
    "                timestepFunc,\n",
    "              arr[:,:,timestep],              \n",
    "                 timestep\n",
    "                ) for timestep in range(arr.shape[2])]\n",
    "#         Gather up the completed tasks\n",
    "        done_results = concurrent.futures.as_completed(futuresList)\n",
    "#     Create the list of results\n",
    "        for _ in futuresList: \n",
    "            resultList.append(next(done_results).result())\n",
    "#         Sort the results back into their original order\n",
    "        resultList = sortResults(resultList=resultList)\n",
    "#     Convert the list of results back into a three-dimensional numpy array\n",
    "    return np.stack(resultList,axis=2)\n",
    "\n",
    "# Run the function with the multiprocessing `ProcessPoolExecutor` and check that the outputs are the same as for the serial processing\n",
    "outputConcurrent = concurrentProcessing(arr=arraySmall,executor=ProcessPoolExecutor)\n",
    "np.testing.assert_array_equal(outputSerial,outputConcurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb883d-7aa4-4325-bd2b-d32ff475f270",
   "metadata": {},
   "source": [
    "## Joblib\n",
    "The joblib library can be either a reimplementation of the built-in `multiprocessing` and `threading` libraries or a wrapper for them. There are some other differences such \n",
    "- as a different way of writing the code that you might find more readable\n",
    "- you can call ctrl-c (= hitting the stop button in a notebook) to interrupt execution of the parallel jobs\n",
    "- ability to use shared memory for large numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3642f7-cb77-4d9a-a63e-a237afe0e8be",
   "metadata": {},
   "source": [
    "Finally we create a function for processing using dask delayed. We test each time to make sure that the outputs are the same in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21284b9-5366-4b00-a0ee-d2b049ab92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joblibProcessing(arr:np.ndarray,backend = \"threading\",maxNbytes=1,nJobs:int=-1):\n",
    "    resultList = Parallel(backend=backend,max_nbytes=maxNbytes,n_jobs=nJobs)(delayed(timestepFunc)(arr[:,:,timestep],timestep) for timestep in range(arr.shape[2]))\n",
    "    resultList = sortResults(resultList=resultList)\n",
    "    return np.stack(resultList,axis=2)\n",
    "\n",
    "outputJoblib = joblibProcessing(arr=arraySmall)\n",
    "np.testing.assert_array_equal(outputSerial,outputJoblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6cdbca2-ccad-4fb2-91bf-22929c084f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daskDelayedProcessing(arr:np.ndarray):\n",
    "    resultList = []\n",
    "    for timestep in range(arr.shape[2]):\n",
    "        resultList.append(\n",
    "            dask.delayed(timestepFunc,pure=False)(arr[:,:,timestep],timestep)\n",
    "        )\n",
    "    resultList = dask.compute(*resultList)\n",
    "    resultList = sortResults(resultList=resultList)\n",
    "    return np.stack(resultList,axis=2)\n",
    "outputDask = daskDelayedProcessing(arr=arraySmall)\n",
    "np.testing.assert_array_equal(outputSerial,outputDask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c016a77-a05e-4ccf-8f18-6245871c378a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f701492-43fa-45d5-8033-e7868e86f478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ebe09-bba3-411f-ba75-cbb7c1bfe928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff0f93-2372-46a1-b432-d32893420178",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyLength = 200\n",
    "timesteps = 2000\n",
    "arrayLarge = generateData(xyLength=xyLength,timesteps=timesteps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536942f2-421c-4a95-a2be-55645c7f89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 serialProcessing(arr=arrayLarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f014e-46f7-4291-a4ae-7795ea267a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 concurrentProcessing(arr=arrayLarge,executor=ProcessPoolExecutor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706005b-8688-4adb-a3e4-0de16bf89bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 concurrentProcessing(arr=arrayLarge,executor=ThreadPoolExecutor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac40ec0-0201-4633-966f-6f9b95405dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab4674-8be2-49f3-bbed-5a6f64fbae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 daskDelayedProcessing(arr=arrayLarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56318fc-e5bd-4d2e-9c1c-93b6fd3da92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 joblibProcessing(arr=arrayLarge,backend=\"threading\")\n",
    "%timeit -n 1 -r 1 joblibProcessing(arr=arrayLarge,backend=\"loky\")\n",
    "%timeit -n 1 -r 1 joblibProcessing(arr=arrayLarge,backend=\"multiprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde69cf-aee8-418d-a1a8-9e941c042afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1262b-7805-492a-97e9-522dbaaa45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f daskDelayedProcessing daskDelayedProcessing(arr=arrayLarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72502a7-a691-48d8-afbc-d4e5ea1efbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit daskDelayedProcessing(SPTimeseries=SPTimeseries,p=p,lon=lon,lat=lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce426364-4c8b-4871-8862-c44b888ee50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_id = ray.put(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df012c-7704-49c8-99fe-f015565fa74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 ray.get(array_id[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc54b3-fdc9-4f1c-9ff8-934efbbcee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
